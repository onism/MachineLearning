{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data= Variable(torch.Tensor([[1.0], [2.0], [3.0]]))\n",
    "y_data= Variable(torch.Tensor([[2.0], [4.0], [6.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = torch.nn.Linear(1,1)\n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionModel()\n",
    "# construct our loss function and an optimizer. The call to model.parameters() in the SGD constructor will \n",
    "#contain the  learnable parameters of thr two nn.Linear modules which are members of the model\n",
    "criterion = torch.nn.MSELoss(size_average=False)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/500], Loss 0.0029\n",
      "Epoch [200/500], Loss 0.0007\n",
      "Epoch [300/500], Loss 0.0002\n",
      "Epoch [400/500], Loss 0.0000\n",
      "Epoch [500/500], Loss 0.0000\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    y_pred = model(x_data)\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    if (epoch+1)%100 == 0:\n",
    "        print('Epoch [{}/{}], Loss {:.4f}'.format(epoch+1, num_epochs, loss))\n",
    "    # zero gradients, perform a backward pass, and update the weights\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('predict :', 4, tensor(7.9966))\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "hour_var = Variable(torch.Tensor([[4.0]]))\n",
    "y_pred = model(hour_var)\n",
    "print(\"predict :\", 4, y_pred.data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.9966]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear regression                                     Logistic regression\n",
    "\n",
    "\\hat y = x * w + b                                    \\hat y = \\sigma(x*w + b) \\sigma(z) = \\frac{1}{1-e^{-z}}\n",
    "\n",
    "\n",
    "loss = 1/N \\sum_{i=1}^N (y - \\hat y)^2                loss = 1/N \\sum_{i=1}^N y_i log \\hat y + (1 - y) log (1 -                                                                               \\hat y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = Variable(torch.Tensor([[1.0], [2.0], [3.0], [4.0]]))\n",
    "y_data = Variable(torch.Tensor([[0.0], [0.], [1.], [1.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(1,1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_pred = F.sigmoid(self.linear(x))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegressionModel()\n",
    "criterion = nn.BCELoss(size_average=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/500], Loss 0.6560\n",
      "Epoch [200/500], Loss 0.6239\n",
      "Epoch [300/500], Loss 0.5993\n",
      "Epoch [400/500], Loss 0.5765\n",
      "Epoch [500/500], Loss 0.5552\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    y_pred = model(x_data)\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    if (epoch+1)%100 == 0:\n",
    "        print('Epoch [{}/{}], Loss {:.4f}'.format(epoch+1, num_epochs, loss))\n",
    "    # zero gradients, perform a backward pass, and update the weights\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('predict 1 hour ', 1.0, tensor(0, dtype=torch.uint8))\n"
     ]
    }
   ],
   "source": [
    "hour_var = Variable(torch.Tensor([[1.0]]))\n",
    "print(\"predict 1 hour \", 1.0, model(hour_var).data[0][0] > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([759, 8])\n",
      "torch.Size([759, 1])\n"
     ]
    }
   ],
   "source": [
    "xy = np.loadtxt('../dataset/diabetes.csv.gz', delimiter=',', dtype=np.float32)\n",
    "x_data = Variable(torch.from_numpy(xy[:,0:-1]))\n",
    "y_data = Variable(torch.from_numpy(xy[:,[-1]]))\n",
    "print(x_data.data.shape)\n",
    "print(y_data.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2941,  0.4874,  0.1803, -0.2929,  0.0000,  0.0015, -0.5312,\n",
      "         -0.0333],\n",
      "        [-0.8824, -0.1457,  0.0820, -0.4141,  0.0000, -0.2072, -0.7669,\n",
      "         -0.6667],\n",
      "        [-0.0588,  0.8392,  0.0492,  0.0000,  0.0000, -0.3055, -0.4927,\n",
      "         -0.6333],\n",
      "        [-0.8824, -0.1055,  0.0820, -0.5354, -0.7778, -0.1624, -0.9240,\n",
      "          0.0000],\n",
      "        [ 0.0000,  0.3769, -0.3443, -0.2929, -0.6028,  0.2846,  0.8873,\n",
      "         -0.6000]])\n",
      "tensor([[ 0.],\n",
      "        [ 1.],\n",
      "        [ 0.],\n",
      "        [ 1.],\n",
      "        [ 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(x_data.data[0:5,:])\n",
    "print(y_data.data[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabetesModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiabetesModel, self).__init__()\n",
    "        self.l1 = nn.Linear(8,6)\n",
    "        self.l2 = nn.Linear(6,4)\n",
    "        self.l3 = nn.Linear(4,1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out1 = self.sigmoid(self.l1(x))\n",
    "        out2 = self.sigmoid(self.l2(out1))\n",
    "        y_pred = self.sigmoid(self.l3(out2))\n",
    "        return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[100/500], Loss0.8555\n",
      "Epoch[200/500], Loss0.8335\n",
      "Epoch[300/500], Loss0.8137\n",
      "Epoch[400/500], Loss0.7960\n",
      "Epoch[500/500], Loss0.7802\n"
     ]
    }
   ],
   "source": [
    "model = DiabetesModel()\n",
    "criterion = nn.BCELoss(size_average=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    y_pred = model(x_data)\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    if (epoch+1)%100 == 0:\n",
    "        print('Epoch[{}/{}], Loss{:.4f}'.format(epoch+1,num_epochs, loss))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
